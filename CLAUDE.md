# CLAUDE.md - AI Assistant Context

**Purpose:** Guide Claude Code when working with this infrastructure repository.

---

## ğŸš¨ CRITICAL RULES

### 1. Documentation Policy
- âœ… **ONLY** update `CLAUDE.md` and `README.md`
- âŒ **NEVER** create additional `.md` files
- **Reason:** Single source of truth, no documentation sprawl

### 2. Secrets Policy
- âœ… Secrets in Kubernetes Secrets only
- âŒ **NEVER** commit secrets to Git
- âœ… Reference secrets in Helm charts via `existingSecret`
- âœ… GitHub push protection will block secret commits

### 3. GitOps Policy
- âœ… All changes via Git commits
- âŒ No manual `kubectl apply` commands (except one-time secret creation)
- âœ… ArgoCD auto-syncs from Git
- âœ… Git is the single source of truth

---

## ğŸ—ï¸ Architecture Overview

**Type:** GitOps-managed Kubernetes infrastructure on K3s
**Platform:** KubeSphere v4.1.3
**GitOps:** ArgoCD with auto-sync enabled
**Ingress:** nginx-ingress controller (NOT Traefik!)
**Auth:** OAuth2 Proxy with Google SSO

### Key Principles

1. **Pure GitOps:** Git push â†’ ArgoCD auto-sync â†’ Kubernetes deploy
2. **Shared Infrastructure:** One PostgreSQL, one Redis, one Kafka UI for all environments
3. **Credential Isolation:** Separate database users (`core_dev_user`, `core_prod_user`)
4. **Environment Separation:** Only applications split dev/prod, infrastructure is shared
5. **Secrets Never in Git:** Use Kubernetes Secrets, GitHub blocks secret commits
6. **nginx-ingress Only:** All ingresses use `ingressClassName: nginx`

---

## ğŸ“ Repository Structure

```
core-charts/
â”œâ”€â”€ README.md                    # User documentation (how-to guides)
â”œâ”€â”€ CLAUDE.md                    # THIS FILE - AI context
â”‚
â”œâ”€â”€ argocd-apps/                 # ArgoCD Application CRDs
â”‚   â”œâ”€â”€ infrastructure.yaml      # Shared infra (sync-wave: 1)
â”‚   â”œâ”€â”€ core-pipeline-dev.yaml   # Dev app (sync-wave: 2)
â”‚   â”œâ”€â”€ core-pipeline-prod.yaml  # Prod app (sync-wave: 2)
â”‚   â””â”€â”€ oauth2-proxy.yaml        # OAuth2 auth (sync-wave: 0)
â”‚
â”œâ”€â”€ charts/
â”‚   â”œâ”€â”€ infrastructure/          # Helm umbrella chart
â”‚   â”‚   â”œâ”€â”€ Chart.yaml           # Remote Bitnami dependencies
â”‚   â”‚   â”œâ”€â”€ values.yaml          # Config (NO secrets!)
â”‚   â”‚   â””â”€â”€ templates/           # Kafka UI resources
â”‚   â”‚
â”‚   â””â”€â”€ core-pipeline/           # Application Helm chart
â”‚       â”œâ”€â”€ values.yaml          # Base config
â”‚       â”œâ”€â”€ values-dev.yaml      # Dev overrides
â”‚       â”œâ”€â”€ values-prod.yaml     # Prod overrides
â”‚       â”œâ”€â”€ dev.tag.yaml         # Dev image tag (triggers deploy)
â”‚       â”œâ”€â”€ prod.tag.yaml        # Prod image tag (triggers deploy)
â”‚       â””â”€â”€ templates/           # K8s manifests
â”‚
â”œâ”€â”€ cert-manager/                # TLS certificates
â”‚   â””â”€â”€ letsencrypt-issuer.yaml  # Let's Encrypt ClusterIssuer
â”‚
â”œâ”€â”€ oauth2-proxy/                # OAuth2 authentication
â”‚   â””â”€â”€ deployment.yaml          # OAuth2 Proxy resources
â”‚
â”œâ”€â”€ setup-oauth2.sh              # Initial OAuth2 setup
â””â”€â”€ create-kafka-ui-oauth2-secret.sh  # Kafka UI OAuth2 secret helper
```

---

## ğŸ¯ Common Tasks for Claude

### Task: Deploy New Application Version

**User says:** "Deploy core-pipeline dev version v1.2.3"

**Actions:**
1. Update `charts/core-pipeline/dev.tag.yaml`: `tag: "v1.2.3"`
2. Commit with message: `"deploy: core-pipeline dev v1.2.3"`
3. Push to GitHub
4. ArgoCD auto-syncs within 3 minutes

**DO NOT:**
- Run `kubectl apply` commands
- Modify infrastructure for application deployments
- Create new namespaces manually

---

### Task: Update Infrastructure Configuration

**User says:** "Increase PostgreSQL memory to 1Gi"

**Actions:**
1. Edit `charts/infrastructure/values.yaml`
2. Find `postgresql.primary.resources.limits.memory`
3. Change value to `1Gi`
4. Commit and push
5. ArgoCD auto-syncs

**DO NOT:**
- Edit pod specs directly
- Use `kubectl patch` or `kubectl edit`

---

### Task: Add New Admin Service

**User says:** "Add MinIO console with OAuth2 protection"

**Actions:**
1. Create deployment in `charts/infrastructure/templates/`
2. Add OAuth2 ingress annotations:
   ```yaml
   nginx.ingress.kubernetes.io/auth-url: "http://oauth2-proxy.oauth2-proxy.svc.cluster.local:4180/oauth2/auth"
   nginx.ingress.kubernetes.io/auth-signin: "https://auth.theedgestory.org/oauth2/start?rd=$scheme://$host$request_uri"
   nginx.ingress.kubernetes.io/auth-response-headers: "X-Auth-Request-User,X-Auth-Request-Email"
   ```
3. Set `ingressClassName: nginx` (NOT traefik!)
4. Add TLS with `cert-manager.io/cluster-issuer: letsencrypt-prod`
5. Commit and push

**DO NOT:**
- Hardcode secrets in templates
- Use Traefik annotations
- Skip OAuth2 protection for admin services

---

### Task: Troubleshoot Deployment Issue

**User says:** "core-pipeline-dev is not deploying"

**Actions:**
1. Check ArgoCD application status:
   ```bash
   kubectl get application core-pipeline-dev -n argocd
   kubectl describe application core-pipeline-dev -n argocd
   ```
2. Check pod status:
   ```bash
   kubectl get pods -n dev-core
   kubectl describe pod <pod-name> -n dev-core
   ```
3. Check logs:
   ```bash
   kubectl logs <pod-name> -n dev-core
   ```

**Common Issues:**
- Image not found â†’ Check `dev.tag.yaml` tag matches Docker registry
- CrashLoopBackOff â†’ Check application logs
- Pending â†’ Check resource limits vs available node resources
- ArgoCD OutOfSync â†’ Check Git commit vs cluster state

---

## ğŸ” Security Architecture

### OAuth2 Multi-Layer Protection

**All admin services protected with Google OAuth2:**

```
User Request
    â†“
Nginx Ingress (TLS termination)
    â†“
OAuth2 Proxy (validates Google login + email whitelist)
    â†“ (sets X-Auth-Request-Email header)
Application (reads email, grants access)
```

**Layer 1 - nginx-ingress:**
- TLS certificate (Let's Encrypt via cert-manager)
- Routes to OAuth2 Proxy for auth check

**Layer 2 - OAuth2 Proxy:**
- Google OAuth2 authentication
- Email whitelist: ONLY `dcversus@gmail.com`
- Sets auth headers for downstream services

**Layer 3 - Applications:**
- **ArgoCD:** Dex authproxy reads `X-Auth-Request-Email` â†’ RBAC grants `role:admin`
- **Kafka UI:** Native OAuth2 + email regex `^dcversus@gmail\.com$`
- **Grafana:** Auth proxy mode with auto-login

**Result:** Unauthorized emails cannot access ANY admin service.

### OAuth2 Configuration Files

**OAuth2 Proxy Deployment:**
- File: `oauth2-proxy/deployment.yaml`
- Google Client ID/Secret: Stored in K8s Secret `oauth2-proxy` (namespace: oauth2-proxy)
- Redirect URI: `https://auth.theedgestory.org/oauth2/callback`
- Cookie domain: `.theedgestory.org` (SSO across all subdomains)

**Kafka UI OAuth2:**
- Client credentials: K8s Secret `kafka-ui-oauth2-secret` (namespace: infrastructure)
- Created by: `create-kafka-ui-oauth2-secret.sh` (reads from oauth2-proxy secret)
- ConfigMap: `charts/infrastructure/templates/kafka-ui-configmap.yaml`
- Ingress: `charts/infrastructure/templates/kafka-ui-ingress.yaml`

---

## ğŸ“Š Namespace & Service Map

| Namespace | Services | Purpose |
|-----------|----------|---------|
| `infrastructure` | PostgreSQL, Redis, Kafka UI | Shared infrastructure |
| `dev-core` | core-pipeline-dev | Development application |
| `prod-core` | core-pipeline-prod (2 replicas) | Production application |
| `argocd` | ArgoCD server, controllers | GitOps deployment platform |
| `cert-manager` | cert-manager | TLS certificate automation |
| `oauth2-proxy` | oauth2-proxy (2 replicas) | Google OAuth2 authentication |
| `kube-system` | nginx-ingress, CoreDNS, metrics-server | System services |

### Service Connections

**core-pipeline-dev connects to:**
- PostgreSQL: `infrastructure-postgresql.infrastructure.svc.cluster.local:5432` (database: `core_dev`, user: `core_dev_user`)
- Redis: `infrastructure-redis-master.infrastructure.svc.cluster.local:6379`

**core-pipeline-prod connects to:**
- PostgreSQL: `infrastructure-postgresql.infrastructure.svc.cluster.local:5432` (database: `core_prod`, user: `core_prod_user`)
- Redis: `infrastructure-redis-master.infrastructure.svc.cluster.local:6379`

**Kafka UI connects to:**
- Kafka: `kafka-cluster-kafka-bootstrap.infrastructure.svc.cluster.local:9092`

---

## ğŸ”§ Common Commands Reference

### ArgoCD Operations

```bash
# Get application status
kubectl get applications -n argocd

# Describe specific app
kubectl describe application infrastructure -n argocd

# Manual sync (if auto-sync is slow)
kubectl patch application infrastructure -n argocd \
  --type merge \
  -p '{"operation":{"sync":{"revision":"HEAD"}}}'

# Access ArgoCD UI
open https://argo.dev.theedgestory.org
```

### Check Deployments

```bash
# All pods across namespaces
kubectl get pods -A

# Infrastructure namespace
kubectl get pods -n infrastructure

# Application namespaces
kubectl get pods -n dev-core
kubectl get pods -n prod-core

# Check ingresses
kubectl get ingress -A
```

### Debugging

```bash
# Pod logs
kubectl logs -n <namespace> <pod-name> -f

# Pod description (events, status)
kubectl describe pod -n <namespace> <pod-name>

# Check certificates
kubectl get certificates -A
kubectl describe certificate <name> -n <namespace>

# Check secrets
kubectl get secrets -n <namespace>
kubectl describe secret <name> -n <namespace>
```

---

## âš ï¸ What NOT to Do

âŒ **Never create additional .md files** (only README.md and CLAUDE.md allowed)
âŒ **Never commit secrets to Git** (GitHub will block, but don't try)
âŒ **Never use Traefik** (infrastructure uses nginx-ingress only)
âŒ **Never skip OAuth2 protection** for admin services
âŒ **Never use `kubectl apply -f`** for GitOps-managed resources (use Git commits)
âŒ **Never create separate infrastructure per environment** (infrastructure is shared)
âŒ **Never hardcode passwords/tokens** in Helm charts

---

## âœ… Best Practices

âœ… **Always use Git commits** for infrastructure changes
âœ… **Always reference secrets** via `existingSecret` in Helm charts
âœ… **Always use nginx-ingress** (`ingressClassName: nginx`)
âœ… **Always add OAuth2 annotations** to admin service ingresses
âœ… **Always use sync-waves** for deployment ordering (ArgoCD)
âœ… **Always set resource limits** for new deployments
âœ… **Always use TLS** with Let's Encrypt (`cert-manager.io/cluster-issuer: letsencrypt-prod`)

---

## ğŸ› Troubleshooting Guide

### Issue: ArgoCD Application OutOfSync

**Diagnosis:**
```bash
kubectl get application <name> -n argocd
kubectl describe application <name> -n argocd | grep -A 20 "Status:"
```

**Causes:**
- Manual `kubectl` changes on cluster (don't do this!)
- Git commit not pulled yet (wait 3 min or manual sync)
- Helm chart syntax errors (check Status.Conditions)

**Fix:**
- If manual changes: Delete resource, let ArgoCD recreate from Git
- If Helm errors: Fix chart syntax in Git, push
- If sync delay: Manual sync via ArgoCD UI or kubectl patch

---

### Issue: Pod CrashLoopBackOff

**Diagnosis:**
```bash
kubectl get pods -n <namespace>
kubectl logs -n <namespace> <pod-name> --previous
kubectl describe pod -n <namespace> <pod-name>
```

**Common Causes:**
- Application error (check logs)
- Missing ConfigMap/Secret (check mounts)
- Wrong database credentials (check secrets)
- Resource limits too low (check resource requests/limits)

---

### Issue: OAuth2 Not Working

**Diagnosis:**
```bash
# Check OAuth2 Proxy
kubectl get pods -n oauth2-proxy
kubectl logs -n oauth2-proxy -l app=oauth2-proxy

# Check ingress annotations
kubectl get ingress <name> -n <namespace> -o yaml | grep -A 5 "annotations:"

# Test without browser cache
curl -I https://<service-url>
```

**Common Causes:**
- OAuth2 Proxy down (check pods)
- Missing ingress annotations (check ingress YAML)
- Wrong redirect URI in Google Console
- Certificate issues (check cert-manager)

**Fix:**
- Ensure ingress has OAuth2 annotations (see "Add New Admin Service" task)
- Check Google Console redirect URIs match
- Verify TLS certificate issued: `kubectl get certificates -A`

---

### Issue: TLS Certificate Not Issuing

**Diagnosis:**
```bash
kubectl get certificates -A
kubectl describe certificate <name> -n <namespace>
kubectl get certificaterequest -A
```

**Common Causes:**
- DNS not pointing to LoadBalancer IP (46.62.223.198)
- Let's Encrypt rate limit (5 per week per domain)
- ClusterIssuer not ready

**Fix:**
- Verify DNS: `dig +short <domain>` should return 46.62.223.198
- Check ClusterIssuer: `kubectl get clusterissuer letsencrypt-prod`
- Wait for cert-manager to retry (automatic)

---

## ğŸ“ Commit Message Conventions

Use conventional commits format:

```bash
# Deployment
deploy: core-pipeline dev v1.2.3

# Configuration change
config: increase PostgreSQL memory to 1Gi

# New feature
feat: add MinIO console with OAuth2 protection

# Bug fix
fix: correct Kafka UI OAuth2 redirect URI

# Infrastructure change
infra: upgrade Redis to 24.0.0

# Security update
security: rotate OAuth2 client secret

# Documentation
docs: update README with new service URLs
```

---

## ğŸ¯ Current Status (October 2025)

### âœ… Fully Deployed

- **GitOps Platform:** ArgoCD with auto-sync
- **Infrastructure:** PostgreSQL 18.0.7, Redis 23.0.10, Kafka UI
- **Applications:** core-pipeline-dev, core-pipeline-prod
- **Authentication:** OAuth2 Proxy with Google SSO
- **TLS:** cert-manager with Let's Encrypt
- **Ingress:** nginx-ingress controller
- **Monitoring:** Prometheus, Grafana

### ğŸ”„ Active

- **Auto-sync:** Enabled on all applications (3min polling)
- **TLS Renewal:** Automatic via cert-manager
- **OAuth2 Session:** Persistent via cookie (domain: .theedgestory.org)

### ğŸ“Š Key Metrics

- **Infrastructure Shared:** âœ… One PostgreSQL, Redis for all environments
- **Credential Isolation:** âœ… Separate DB users (core_dev_user, core_prod_user)
- **Security:** âœ… OAuth2 on all admin services, only dcversus@gmail.com allowed
- **GitOps Compliance:** âœ… 100% (no manual kubectl for managed resources)
- **Secrets in Git:** âŒ None (GitHub push protection enforced)

---

## ğŸš€ Quick Reference Card

**When user wants to:**

| User Request | Action | File to Edit |
|--------------|--------|-------------|
| Deploy new app version | Update tag | `charts/core-pipeline/{dev\|prod}.tag.yaml` |
| Change PostgreSQL config | Edit values | `charts/infrastructure/values.yaml` |
| Change Redis config | Edit values | `charts/infrastructure/values.yaml` |
| Add new admin service | Add templates | `charts/infrastructure/templates/` |
| Update OAuth2 whitelist | Edit ConfigMap | `oauth2-proxy/deployment.yaml` (email list) |
| Check deployment status | ArgoCD UI | https://argo.dev.theedgestory.org |
| View app logs | Grafana or kubectl | https://grafana.dev.theedgestory.org |
| Rollback deployment | Git revert | `git revert <commit-hash>` |

---

**Last Updated:** October 2025
**Infrastructure Version:** v1.0
**ArgoCD:** Auto-sync enabled (3min polling)
**Server:** 46.62.223.198 (K3s cluster)
